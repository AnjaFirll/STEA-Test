{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import df_construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(r\"D:\\Textkernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_MONTH = '2020-07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_format = (\n",
    "    '[%(asctime)s] %(levelname)-8s %(name)-12s %(message)s')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=log_format,\n",
    "    # Declare handlers\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        logging.FileHandler('debug_%s.log'%YEAR_MONTH),\n",
    "    ]\n",
    ")\n",
    "# Define your own logger name\n",
    "logger = logging.getLogger(\"my_logger_%s\"%YEAR_MONTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diese Funktion iteriert für einen gegebenen Monat über alle (bekannten) Regionen, verwendet diese als Input für die \"get_month_region\" Funktionen, vergleich die Anzahl der STEAs und speichert das Dataframe als JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_month_2(month_select):\n",
    "    \n",
    "    \n",
    "    ergebnis = DataFrame()\n",
    "    #Achtung es gibt eine 17. Region (UN=Unbekannt)\n",
    "    \n",
    "    ##Achtung ! Eine Region ohne Einträge in einem ganzen Monat (vor aallem UN ) scheint Fehler zu verursachen \n",
    "    #region = ['BE','SL','RP','BB','MV','SH','ST','SN','HH','BW','NI','TH','UN','HB','NW','BY','HE' ]\n",
    "    \n",
    "    region = [ 'NW','BE','MV','SH','ST','SN','HH','NI','TH','HB','SL','HE','BB','BW','RP','BY' ]\n",
    "    \n",
    "    ##ACTHUnG TEST!!\n",
    "    #region = ['BE','SL','BW','RP' ]\n",
    " \n",
    "    \n",
    "\n",
    "    counter = 0\n",
    "    region_counter = 0\n",
    "    agg2 = df_construct.aggregate_month(month_select)\n",
    "    \n",
    "    logger.info(\"Anzahl Regionen  \"+str(len(region)))\n",
    "\n",
    "    for r in region:\n",
    "        # record start time\n",
    "        start = time.time()\n",
    "        region_counter+= 1\n",
    "        \n",
    "        filename = get_filename(month_select,r)\n",
    "        #pfad eingefuegt\n",
    "        path = 'O:/AB12/A12/QEF-STELLENANZEIGEN/_QEF-STELLENANZEIGEN/4_Daten/4_TK_data/NeueDaten080223_AF/'\n",
    "        filename = os.path.join(path,'TK_'+YEAR_MONTH,filename+'.json')\n",
    "        if os.path.exists(filename):\n",
    "            logger.debug ('%s: file %s already exists.'%(region_counter,filename))\n",
    "            continue\n",
    "        logger.debug ('%s: processing %s ...'%(region_counter,filename))\n",
    "            \n",
    "        ##NEU\n",
    "        df_construct.toobig = False\n",
    "        \n",
    "        #Neue Retry Funktion\n",
    "        ergebnis_r = df_construct.get_month_region_retry(r,month_select)\n",
    "        \n",
    "        ##Neu\n",
    "        \n",
    "        agg1 = df_construct.aggregate_month_region(r,month_select)\n",
    "        \n",
    "        ##Wie viele Anzeigen runtergeladen\n",
    "        counter = counter + len(ergebnis_r)\n",
    "        \n",
    "        ##NEU nach JSON per Monat/Region\n",
    "        \n",
    "        #NEU!\n",
    "        #filename = get_filename(month_select,r)\n",
    "        write_json(filename,ergebnis_r)\n",
    "        \n",
    "        ##NEU! Für den 2ten Teil des Programms muss der Filename verfügbar sein\n",
    "        \n",
    "        files.append(filename)\n",
    "        \n",
    "        ## Die Daten über die heruntergeladenen STEAS \n",
    "        mdata = []\n",
    "        \n",
    "        ##Monat/Jahr Region und heruntergeladene Steas\n",
    "        #mdata.append(month_select)\n",
    "        \n",
    "        #NEU!!!\n",
    "        jahr = month_select.split('-')[0]\n",
    "        monat= month_select.split('-')[1]\n",
    "        \n",
    "        mdata.append(jahr)\n",
    "        mdata.append(monat)\n",
    "        \n",
    "        ###\n",
    "        \n",
    "        mdata.append(r)\n",
    "        mdata.append(len(ergebnis_r))\n",
    "        \n",
    "        ## Steas für diesen Monat/Jahr/Region die aktuelle Anzahl der Steas in allen Downloads und die Anzahl der Steas für\n",
    "        ## den gesamten Monat des Jahres (mit den unbekannten Regionen)\n",
    "        mdata.append(agg1)\n",
    "        mdata.append(counter)\n",
    "        mdata.append(agg2)\n",
    "        \n",
    "        ##Und der Dateiname für später\n",
    "        mdata.append(filename)\n",
    "        \n",
    "        ##TEST die globale Variable für zu große Tage\n",
    "        mdata.append(df_construct.toobig)\n",
    "        \n",
    "        ##Tupel wird der globalen Variable hinzugefügt\n",
    "        metadata.append(mdata)\n",
    "        \n",
    "        ## Speicher wieder freigeben \n",
    "        mdata = None\n",
    "        ergebnis_r = None\n",
    "    \n",
    "        # record execution time\n",
    "        executionTime = (time.time () - start) \n",
    "\n",
    "        # print the difference between start\n",
    "        # and end time in milli. secs\n",
    "        logger.debug(\"The time of execution of PROCESSING df for region %s : %s\"%(r, sec_to_hms(int(executionTime))))\n",
    "      \n",
    "    \n",
    "    logger.debug(\"Programm fertig\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NEU Funktion soll weiter helfen die Dateinamen zu vereinheitlichen \n",
    "def get_filename(month,region):\n",
    "    \n",
    "    filename = \"TK_\"+month+\"_\"+region\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Die Ausgabe ist für die json --> DB Funktion gedacht \n",
    "def get_month(filename):\n",
    "    \n",
    "    month = filename[3:10]\n",
    "  \n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_hms(seconds):\n",
    "    h = seconds // 3600\n",
    "    m = seconds % 3600 // 60\n",
    "    s = seconds % 3600 % 60\n",
    "    return f'{h:02d}:{m:02d}:{s:02d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NEUE Parameter\n",
    "def write_json(filename,df):\n",
    "    # record start time\n",
    "    start = time.time()\n",
    "    \n",
    "    #Das macht die Funtion nun nicht mehr selbst\n",
    "    #filename = month+region\n",
    "    \n",
    "    \n",
    "    logger.debug(\"Schreibe als json:  \"+filename)\n",
    "    print(\"Schreibe als json:  \"+filename,file=text_file)\n",
    "    \n",
    "    \n",
    "    ##Sollte Force_Ascii nicht true sein: NEIN für Textkernel und Co brauch man Latin-1 encoding NICHT utf-8\n",
    "    df.to_json(filename+\".json\", orient=\"records\", force_ascii = False)\n",
    "    \n",
    "    ##df.to_json(filename+\".json\", orient=\"records\", force_ascii = True)\n",
    "    \n",
    "    logger.debug(\"JSON Datei erstellt\")\n",
    "    print(\"JSON Datei erstellt\",file=text_file)\n",
    "    \n",
    "    # record execution time\n",
    "    executionTime = (time.time () - start) \n",
    "\n",
    "    # print the difference between start\n",
    "    # and end time in milli. secs\n",
    "    logger.debug(\"The time of execution of writing on json is : %s\",\n",
    "          sec_to_hms(int(executionTime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Der Februar ist der Monat mit den meisten Einträgen\n",
    "### Format YYYY-MM\n",
    "def testlauf():\n",
    "    \n",
    "    months = [YEAR_MONTH] #,'2022-05','2022-06','2022-07','2022-08','2021-06','2021-07','2021-08','2021-09','2021-10','2021-11','2021-12','2022-01','2022-02','2022-03','2022-04']\n",
    "    \n",
    "    for m in months:\n",
    "        get_complete_month_2(m)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Startpunkt für das Progrtamm (Teil 1) , initialisiert eine Variable die den Zugriff für die Log Datei enthält sowie zwei Arrays die global vorliegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-03 15:54:58,715] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:54:59,198] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/aggregate?date__range=2020-07-01__2020-07-01%7C%7C%2B1M-1d%0A%0A HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:54:59,201] INFO     my_logger_2020-07 Anzahl Regionen  16\n",
      "[2023-03-03 15:54:59,205] DEBUG    my_logger_2020-07 1: processing O:/AB12/A12/QEF-STELLENANZEIGEN/_QEF-STELLENANZEIGEN/4_Daten/4_TK_data/NeueDaten080223_AF/TK_2020-07\\TK_2020-07_NW.json ...\n",
      "[2023-03-03 15:55:02,225] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:55:02,736] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/aggregate?date__range=2020-07-01__2020-07-01%7C%7C%2B1M-1d%0A%0A&region=NW HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:55:05,749] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:55:08,767] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-01&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:55:13,588] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:55:18,744] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-02&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:55:24,675] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:55:29,106] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-03&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:55:35,136] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:55:39,736] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-04&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:55:45,155] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:55:47,283] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-05&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:55:51,400] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:55:54,109] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-06&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:55:58,510] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:56:03,344] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-07&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:56:08,759] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:56:13,372] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-08&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:56:19,570] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:56:24,743] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-09&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:56:30,686] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:56:34,901] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-10&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:56:40,483] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:56:43,795] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-11&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n",
      "[2023-03-03 15:56:48,966] DEBUG    urllib3.connectionpool Starting new HTTPS connection (1): www.jobfeed.de:443\n",
      "[2023-03-03 15:56:51,433] DEBUG    urllib3.connectionpool https://www.jobfeed.de:443 \"GET /api/v3/search?region=NW&date=2020-07-12&_limit=10000&_labels=0 HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "## Hier starten\n",
    "\n",
    "##Dieser Array wird Stück für Stück befüllt auch wenn testlauf() abbricht sind die Daten nicht weg!\n",
    "## Diese Variable bleibt vorläufig erhalten das sie Stück für Stück befüllt wird \n",
    "\n",
    "files = []\n",
    "\n",
    "## Diese Daten müssen auch in  einem Array erfasst werden und erst dann in ein dataframe und dann json umgewandelt werden\n",
    "metadata = []\n",
    "\n",
    "\n",
    "##Globale Variable zur Erfassung von Tagen mit 10000+ Einträgen\n",
    "df_construct.toobig = False\n",
    "\n",
    "text_file = open((\"txt_kernel_download_log_01092022_neu_skills_%s.txt\"%YEAR_MONTH), \"a\")\n",
    "\n",
    "#Kopie für Modul TEST\n",
    "df_construct.text_file=text_file\n",
    "\n",
    "\n",
    "testlauf()\n",
    "\n",
    "\n",
    "print(files)\n",
    "\n",
    "## Erstellung der JSON mit den Daten des Vorgangs\n",
    "df_meta = pd.DataFrame(metadata, columns =['Jahr','Monat', 'Region','SteasDownload','SteasMonatRegion','SteasDownloadTotal','SteasMonatTotal','Dateiname','TagZuGross']) \n",
    "df_meta\n",
    "\n",
    "write_json('testlauf1_%s'%YEAR_MONTH,df_meta)\n",
    "\n",
    "\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_file = open(\"txt_kernel_LOG.txt\", \"a\")\n",
    "\n",
    "#Kopie für Modul TEST\n",
    "df_construct.text_file=text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=  df_construct.get_month_region_retry('BW','2022-08')\n",
    "print(df_construct.toobig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotheken und globale Variablen für die Befüllung der DB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hier findet der 2.Teil statt in dem der Transfer in die DB getestet wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x = pd.read_json(\"df_error.json\")\n",
    "\n",
    "x = pd.read_json(\"TK_2021-03_BE.json\",orient=\"records\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['it_skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = x.index\n",
    "columns = x.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[x['it_skill_terms']=='[LabView]']\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[\"Monat\"]= x[\"Dateiname\"].apply(lambda x: x[-5:-3]) Nicht mehr nötig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = x['Dateiname'].tolist() ##Abgeöndert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NEUE Tests\n",
    "\n",
    "text_file = open(\"txt_kernel_test_NEU.txt\", \"a\")\n",
    "#test = get_month_region_retry('2020-04','BW')\n",
    "\n",
    "#Kopie für Modul TEST\n",
    "df_construct.text_file=text_file\n",
    "\n",
    "\n",
    "##Wichtig !  Region + Monat mir Tag über 10000 Einträgen\n",
    "#test=  df_construct.get_month_region_retry('BW','2020-01')\n",
    "\n",
    "#test=  df_construct.get_month_region_retry('BW','2020-04')\n",
    "test=  df_construct.get_month_region_retry('SL','2018-03')\n",
    "\n",
    "#test=  df_construct.get_month_region_retry('2020-04','BW')\n",
    "#construct_day('2020-04','BE','23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test\n",
    "len(test.job_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"agg_test.txt\", \"a\")\n",
    "#test = get_month_region_retry('2020-04','BW')\n",
    "\n",
    "#Kopie für Modul TEST\n",
    "df_construct.text_file=text_file\n",
    "x = df_construct.aggregate_month_region(\"SL\",\"2018-03\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_json('TK_2020-08_BE.json',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
